{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['prompt', 'predict', 'label'])\n",
      "7500\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "dataset_root = '../MATH/train/'\n",
    "\n",
    "with open(os.path.join(dataset_root, 'train_dataset_eval.jsonl'), 'r') as f:\n",
    "    lines = f.readlines()\n",
    "\n",
    "data = [json.loads(line) for line in lines]\n",
    "\n",
    "print(data[0].keys())\n",
    "print(len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "from tqdm import tqdm\n",
    "\n",
    "client = OpenAI(\n",
    "    api_key=os.environ.get(\"OPENAI_API_KEY\"),\n",
    "    base_url=os.environ.get(\"OPENAI_API_BASE\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def compare_boxed_contents(str1, str2):\n",
    "    # Regular expression to match the pattern \\boxed{content}\n",
    "    pattern = r'\\\\boxed\\{(.*?)\\}'\n",
    "    \n",
    "    # Find all occurrences of \\boxed{content} in both strings\n",
    "    match1 = re.search(pattern, str1)\n",
    "    match2 = re.search(pattern, str2)\n",
    "    \n",
    "    # Check if both strings contain the \\boxed{} pattern and compare their contents\n",
    "    if match1 and match2:\n",
    "        return match1.group(1) == match2.group(1)\n",
    "    return False  # Return False if either string does not contain a \\boxed{}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tweak(sample, client):\n",
    "    question = sample['prompt']\n",
    "    student_answer = sample['predict']\n",
    "    ground_truth = sample['label']\n",
    "    \n",
    "    try:\n",
    "        response = client.chat.completions.create(\n",
    "            model=\"gpt-4o-mini\",\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": \"You are a helpful assistant specializing in generating well structured explanations for educational content.\"},\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": f\"\"\"You are a teacher model tasked with improving a student's mathematical answer. The goal is to help the student learn and correct their mistakes, not by simply providing the correct solution, but by modifying the student's answer to make it more accurate. You will receive the following inputs:\n",
    "Question: The original math problem the student was asked to solve.\n",
    "Student's Answer: The answer the student has provided for the question.\n",
    "Ground Truth Answer: The correct, intended solution to the problem.\n",
    "\n",
    "Your task is to output a tweaked answer that follows the general idea of the student, but correct the mistakes along the way. Your tweaked answer should look like the student has learned from the mistakes and paying attention to what the teacher is saying.\n",
    "\n",
    "Some requirements you need to meet:\n",
    "1. Do not make the answet too long! The student should learn to generate a concise and correct answer!\n",
    "2. Use latex to show the expressions, but do not format the text using \\\\text{{}} or \\\\textbf{{}} commands.\n",
    "3. Use single dollar sign instead of double $$ sign to wrap the latex expressions. This inline math mode is more suitable for the student's level.\n",
    "4. Use the \\\\boxed{{}} command to highlight the final answer! Use the \\\\boxed{{}} command to highlight the final answer!\n",
    "\n",
    "Question: {question}\\nStudent answer: {student_answer}\\nGround truth: {ground_truth}\\nYour tweaked answer is:\"\"\"\n",
    "                }\n",
    "            ]\n",
    "        )\n",
    "        tweaked_answer = response.choices[0].message.content\n",
    "        sample['tweak'] = tweaked_answer\n",
    "        \n",
    "    except Exception as e:\n",
    "        pass\n",
    "        \n",
    "    return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1603/1603 [1:25:42<00:00,  3.21s/it]\n"
     ]
    }
   ],
   "source": [
    "train_tweak_path = os.path.join(dataset_root, 'train_tweak.jsonl')\n",
    "for ix, sample in tqdm(enumerate(data[5897:]), total=len(data[5897:])):\n",
    "    if not compare_boxed_contents(sample['predict'], sample['label']):\n",
    "        sample = tweak(sample, client)\n",
    "    with open(train_tweak_path, 'a') as f:\n",
    "        f.write(json.dumps(sample) + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7509\n"
     ]
    }
   ],
   "source": [
    "with open(train_tweak_path, 'r') as f:\n",
    "    lines = f.readlines()\n",
    "\n",
    "data = [json.loads(line) for line in lines]\n",
    "print(len(data))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cu121",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
