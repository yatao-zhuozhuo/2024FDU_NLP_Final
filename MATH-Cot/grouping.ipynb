{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get embeddings of sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get questions in train.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7500\n",
      "{'1': {'conversations': [{'from': 'human', 'value': 'What is the value of $-a-b^3+ab$ if $a=-3$ and $b=2$?'}, {'from': 'gpt', 'value': 'Plugging in the given values yields $-a-b^3+ab=-(-3)-2^3+(-3)(2)=3-8-6=\\\\boxed{-11}$.'}], 'system': 'You are a helpful assistant skilled in solving mathematical problems. Provide step-by-step explanations for each solution and ensure clarity in reasoning.', 'tools': {'calculator': {'description': 'A basic calculator tool to perform arithmetic operations.', 'enabled': True, 'functions': ['add', 'subtract', 'multiply', 'divide']}, 'algebra_solver': {'description': 'An algebra solver tool to simplify equations and solve for unknowns.', 'enabled': True, 'functions': ['simplify', 'solve']}}}}\n"
     ]
    }
   ],
   "source": [
    "from utils import *\n",
    "import os\n",
    "\n",
    "dataset_root = '../MATH/train/'\n",
    "\n",
    "with open(os.path.join(dataset_root, 'train.json'), 'r') as f:\n",
    "    data = json.load(f)\n",
    "print(len(data))\n",
    "# print(data[1]['1']['conversations'])\n",
    "print(data[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of questions: 7500\n",
      "\n",
      "First 5 questions:\n",
      "A rectangle having integer length and width has a perimeter of 100 units. What is the number of square units in the least possible area?\n",
      "What is the value of $-a-b^3+ab$ if $a=-3$ and $b=2$?\n",
      "Find the radius of the circle with equation $x^2 - 6x + y^2 + 2y + 6 = 0$.\n",
      "Solve for $x$: $4x^{1/3}-2 \\cdot \\frac{x}{x^{2/3}}=7+\\sqrt[3]{x}$.\n",
      "What is the sum of all of the solutions of the equation $\\frac{4x}{20}=\\frac{5}{x}$?\n"
     ]
    }
   ],
   "source": [
    "# Extract human questions\n",
    "questions = []\n",
    "for item in data:\n",
    "    for key, conversations in item.items():\n",
    "        for conv in conversations['conversations']:\n",
    "            if conv['from'] == 'human':\n",
    "                questions.append(conv['value'])\n",
    "\n",
    "# Print the total number of questions and the first few\n",
    "print(f\"Total number of questions: {len(questions)}\")\n",
    "print(\"\\nFirst 5 questions:\")\n",
    "for q in questions[:5]:\n",
    "    print(q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n",
      "Embedding shape: torch.Size([7500, 768])\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "import torch\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(f'Device: {device}')\n",
    "\n",
    "# Load a lightweight transformer model\n",
    "model = SentenceTransformer('all-distilroberta-v1', device=device)\n",
    "\n",
    "# Compute sentence embeddings\n",
    "embeddings = model.encode(questions, convert_to_tensor=True)\n",
    "\n",
    "# Optional: check tensor shape\n",
    "print(\"Embedding shape:\", embeddings.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13, 15, 8, 15, 15, 8, 8, 10, 15, 17]\n"
     ]
    }
   ],
   "source": [
    "group_numbers = cluster_embeddings(embeddings, num_clusters=20)  # Example: 10 clusters\n",
    "\n",
    "# Print the first 10 group numbers\n",
    "print(group_numbers[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{13: 189, 15: 583, 8: 409, 10: 301, 17: 412, 2: 329, 5: 412, 14: 316, 12: 699, 3: 374, 0: 360, 7: 297, 18: 514, 19: 272, 4: 245, 6: 377, 1: 418, 9: 355, 11: 242, 16: 396}\n"
     ]
    }
   ],
   "source": [
    "print(count_items_in_groups(group_numbers))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Choose the top 8 question that is most close to the mean of each group."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'0': [4504, 3003, 3722, 3575, 3623, 4255, 3938, 3436], '1': [4603, 4750, 7094, 3351, 2511, 7188, 4846, 2917], '2': [3874, 4370, 4515, 4377, 4188, 4024, 4369, 4489], '3': [1937, 1765, 2317, 6467, 3797, 2264, 2485, 3952], '4': [3906, 3791, 3778, 3753, 3808, 1851, 4027, 2299], '5': [2748, 2593, 3552, 2909, 3267, 3149, 2785, 3480], '6': [7412, 6843, 3549, 3301, 7436, 7168, 7227, 3025], '7': [6468, 6710, 6165, 6046, 5867, 5821, 6322, 5770], '8': [256, 5, 1175, 1669, 794, 6124, 398, 6556], '9': [7293, 5417, 7045, 7199, 6953, 6838, 6851, 7421], '10': [6458, 6620, 141, 6116, 6550, 6587, 6229, 5815], '11': [2238, 2343, 2048, 1835, 2181, 1775, 1768, 2404], '12': [4642, 5427, 5261, 4825, 5305, 5181, 5348, 5150], '13': [4519, 2904, 3533, 3085, 2807, 2880, 2869, 3275], '14': [1592, 1369, 1641, 642, 892, 220, 199, 554], '15': [6208, 605, 2948, 2547, 947, 139, 1409, 2756], '16': [3692, 3401, 3662, 3390, 3316, 4015, 4483, 4542], '17': [403, 6395, 5658, 5960, 1583, 69, 1318, 1054], '18': [4220, 1575, 861, 2867, 1564, 952, 5110, 2664], '19': [6384, 6044, 5947, 6362, 5476, 5493, 6404, 6166]}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_34958/4203012270.py:6: DeprecationWarning: __array__ implementation doesn't accept a copy keyword, so passing copy=False failed. __array__ must implement 'dtype' and 'copy' keyword arguments.\n",
      "  embeddings = np.array(embeddings.cpu())\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def select_top_questions_per_group(group_numbers, questions, embeddings):\n",
    "    # Convert inputs to numpy arrays for efficient processing\n",
    "    group_numbers = np.array(group_numbers)\n",
    "    embeddings = np.array(embeddings.cpu())\n",
    "    \n",
    "    # Get unique groups\n",
    "    unique_groups = np.unique(group_numbers)\n",
    "    \n",
    "    # Dictionary to store top 8 indices for each group\n",
    "    top_questions_per_group = {}\n",
    "    \n",
    "    for group in unique_groups:\n",
    "        # Find indices of questions in this group\n",
    "        group_indices = np.where(group_numbers == group)[0]\n",
    "        \n",
    "        # Get embeddings for this group\n",
    "        group_embeddings = embeddings[group_indices]\n",
    "        \n",
    "        # Calculate the mean embedding for the group\n",
    "        group_mean = np.mean(group_embeddings, axis=0)\n",
    "        \n",
    "        # Calculate distances from group mean\n",
    "        distances = np.linalg.norm(group_embeddings - group_mean, axis=1)\n",
    "        \n",
    "        # Get indices of 8 closest questions (or fewer if group is smaller)\n",
    "        top_8_local_indices = np.argsort(distances)[:8]\n",
    "        \n",
    "        # Map local indices back to original indices\n",
    "        top_8_global_indices = group_indices[top_8_local_indices]\n",
    "        \n",
    "        # Store in dictionary\n",
    "        top_questions_per_group[str(group)] = top_8_global_indices.tolist()\n",
    "    \n",
    "    return top_questions_per_group\n",
    "\n",
    "# Usage would look like:\n",
    "result = select_top_questions_per_group(group_numbers, questions, embeddings)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['0', '1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19'])\n",
      "8\n"
     ]
    }
   ],
   "source": [
    "def construct_grouped_dataset(data, result):\n",
    "    # Initialize a dictionary to store grouped data\n",
    "    grouped_dataset = {}\n",
    "    \n",
    "    # Iterate through the result dictionary\n",
    "    for group, indices in result.items():\n",
    "        # Select items from data using the indices\n",
    "        grouped_dataset[group] = [data[idx] for idx in indices]\n",
    "    \n",
    "    return grouped_dataset\n",
    "\n",
    "# Usage would look like:\n",
    "grouped_dataset = construct_grouped_dataset(data, result)\n",
    "print(grouped_dataset.keys())\n",
    "print(len(grouped_dataset['0']))  # number of items in group 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(os.path.join(dataset_root, 'train_gr20_samples.json'), 'w') as f:\n",
    "#     json.dump(grouped_dataset, f, indent=2)\n",
    "\n",
    "if len(group_numbers) == len(data):\n",
    "    for i, item in enumerate(data):\n",
    "        for key, val in item.items():\n",
    "            val['group_number'] = group_numbers[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['conversations', 'system', 'tools', 'group_number'])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0]['0'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(dataset_root, 'train_gr20.json'), 'w') as f:\n",
    "    json.dump(data, f, indent=2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cu121",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
